{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame The Problem\n",
    "1. **Define the objective in business terms.**\n",
    "- We have been hired by the National Wildlife Service, they have cameras they want to use to track staple wild animal populations, specifically birds, deer, and frogs, with their cameras and statistical models. Cats and dogs can also affect the environment, so they make sure people's pets do not kill off the wild animal populations. Other images of horses, airplanes, automobiles, ships, and trucks are often caught on these cameras and are of little use to the service, but they want to be tracked because some papers have suggested that noise pollution from these can affect animal and plant populations.\n",
    "2. **How will your solution be used?**\n",
    "- Our solution will predict what pictures are in bulk allowing National Wildlife Service to plug the numbers into their statistically models.\n",
    "3. **What are the current solutions/workarounds (if any)?**\n",
    "- Currently they have unpaid interns look at photos one by one labeling them to count animals.\n",
    "4. **How should you frame this problem (supervised/unsupervised, online/offline, ...)?**\n",
    "- It is a supervised task, it does not need to be online.\n",
    "5. **How should performance be measured? Is the performance measure aligned with the business objective?**\n",
    "6. **What would be the minimum performance needed to reach the business objective?**\n",
    "7. **What are comparable problems? Can you reuse experience or tools?**\n",
    "8. **Is human expertise available?**\n",
    "9. **How would you solve the problem manually?**\n",
    "10. **List the assumptions you (or others) have made so far. Verify assumptions if possible.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_words = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\n",
    "def get_label(index:list):\n",
    "    labels = []\n",
    "    for i in index:\n",
    "        labels.append(label_words[i])\n",
    "    return labels\n",
    "\n",
    "def unpickle(has_validation=True):\n",
    "    files = ['data_batch_1', 'data_batch_2', 'data_batch_3','data_batch_4']\n",
    "    if has_validation:\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_val = []\n",
    "        y_val = []\n",
    "        data = None\n",
    "        for file in files:\n",
    "            with open('data/'+file, 'rb') as fo:\n",
    "                data = pickle.load(fo, encoding='bytes')\n",
    "                y_train += list(data[b'labels'])\n",
    "                X_train += list(data[b'data'])\n",
    "\n",
    "        with open('data/data_batch_4', 'rb') as fo:\n",
    "            data = pickle.load(fo, encoding='bytes')\n",
    "            y_val = list(data[b'labels'])\n",
    "            X_val = list(data[b'data'])\n",
    "\n",
    "        with open('data/test_batch', 'rb') as fo:\n",
    "            data = pickle.load(fo, encoding='bytes')\n",
    "            y_test = list(data[b'labels'])\n",
    "            X_test = list(data[b'data'])\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    else:\n",
    "        files = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "        y_train = []\n",
    "        X_train = [] \n",
    "        data = None\n",
    "        for file in files:\n",
    "            with open('data/'+file, 'rb') as fo:\n",
    "                data = pickle.load(fo, encoding='bytes')\n",
    "                y_train += list(data[b'labels'])\n",
    "                X_train += list(data[b'data'])\n",
    "\n",
    "        with open('data/test_batch', 'rb') as fo:\n",
    "            data = pickle.load(fo, encoding='bytes')\n",
    "            y_test = list(data[b'labels'])\n",
    "            X_test = list(data[b'data'])\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "\n",
    "def plot_cifar10_images(images, labels):\n",
    "    axes = plt.subplots(5, 5, figsize=(10, 10))[1]\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            index = i * 5 + j\n",
    "            image = images[index].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "            axes[i, j].imshow(image)\n",
    "            axes[i, j].set_title(labels[index])\n",
    "            axes[i, j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = unpickle(has_validation=True)\n",
    "# Reshape the data\n",
    "X_train = np.array(X_train).reshape(-1, 32, 32, 3)\n",
    "X_valid = np.array(X_valid).reshape(-1, 32, 32, 3)\n",
    "X_test = np.array(X_test).reshape(-1, 32, 32, 3)\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "X_test = X_test / 255.0\n",
    "# Reshape the labels\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_valid = np.array(y_valid).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2342 - loss: 2.0737 - val_accuracy: 0.3408 - val_loss: 1.8356\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.3531 - loss: 1.8138 - val_accuracy: 0.3852 - val_loss: 1.7387\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.3878 - loss: 1.7164 - val_accuracy: 0.4082 - val_loss: 1.6678\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.4071 - loss: 1.6680 - val_accuracy: 0.4290 - val_loss: 1.6234\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.4197 - loss: 1.6182 - val_accuracy: 0.4461 - val_loss: 1.5826\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.4352 - loss: 1.5891 - val_accuracy: 0.4576 - val_loss: 1.5448\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 0.4457 - loss: 1.5653 - val_accuracy: 0.4584 - val_loss: 1.5578\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.4491 - loss: 1.5486 - val_accuracy: 0.4604 - val_loss: 1.5308\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.4561 - loss: 1.5181 - val_accuracy: 0.4627 - val_loss: 1.5112\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.4725 - loss: 1.5036 - val_accuracy: 0.4792 - val_loss: 1.4739\n"
     ]
    }
   ],
   "source": [
    "# basic MLP\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[32, 32, 3]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2382 - loss: 2.0852 - val_accuracy: 0.3536 - val_loss: 1.7982 - learning_rate: 0.0100\n",
      "Epoch 2/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3602 - loss: 1.7735 - val_accuracy: 0.3790 - val_loss: 1.7184 - learning_rate: 0.0100\n",
      "Epoch 3/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3937 - loss: 1.6791 - val_accuracy: 0.4067 - val_loss: 1.6691 - learning_rate: 0.0100\n",
      "Epoch 4/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4228 - loss: 1.6139 - val_accuracy: 0.4393 - val_loss: 1.5708 - learning_rate: 0.0100\n",
      "Epoch 5/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4338 - loss: 1.5800 - val_accuracy: 0.4401 - val_loss: 1.5702 - learning_rate: 0.0100\n",
      "Epoch 6/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4463 - loss: 1.5391 - val_accuracy: 0.4590 - val_loss: 1.5182 - learning_rate: 0.0100\n",
      "Epoch 7/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4572 - loss: 1.5214 - val_accuracy: 0.4703 - val_loss: 1.4780 - learning_rate: 0.0100\n",
      "Epoch 8/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4656 - loss: 1.4849 - val_accuracy: 0.4810 - val_loss: 1.4607 - learning_rate: 0.0100\n",
      "Epoch 9/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4704 - loss: 1.4684 - val_accuracy: 0.4928 - val_loss: 1.4302 - learning_rate: 0.0100\n",
      "Epoch 10/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4821 - loss: 1.4459 - val_accuracy: 0.4800 - val_loss: 1.4550 - learning_rate: 0.0100\n",
      "Epoch 11/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4889 - loss: 1.4203 - val_accuracy: 0.4794 - val_loss: 1.4503 - learning_rate: 0.0100\n",
      "Epoch 12/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4912 - loss: 1.4131 - val_accuracy: 0.4847 - val_loss: 1.4495 - learning_rate: 0.0100\n",
      "Epoch 13/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5210 - loss: 1.3389 - val_accuracy: 0.5237 - val_loss: 1.3337 - learning_rate: 1.0000e-03\n",
      "Epoch 14/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5249 - loss: 1.3279 - val_accuracy: 0.5237 - val_loss: 1.3313 - learning_rate: 1.0000e-03\n",
      "Epoch 15/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5268 - loss: 1.3171 - val_accuracy: 0.5291 - val_loss: 1.3291 - learning_rate: 1.0000e-03\n",
      "Epoch 16/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5303 - loss: 1.3127 - val_accuracy: 0.5264 - val_loss: 1.3222 - learning_rate: 1.0000e-03\n",
      "Epoch 17/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5273 - loss: 1.3138 - val_accuracy: 0.5321 - val_loss: 1.3182 - learning_rate: 1.0000e-03\n",
      "Epoch 18/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5309 - loss: 1.3037 - val_accuracy: 0.5306 - val_loss: 1.3158 - learning_rate: 1.0000e-03\n",
      "Epoch 19/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5366 - loss: 1.2907 - val_accuracy: 0.5316 - val_loss: 1.3134 - learning_rate: 1.0000e-03\n",
      "Epoch 20/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5343 - loss: 1.3031 - val_accuracy: 0.5302 - val_loss: 1.3115 - learning_rate: 1.0000e-03\n"
     ]
    }
   ],
   "source": [
    "# selu activation \"lecun_normal\"\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[32, 32, 3]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(50, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(50, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(50, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(50, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.2661 - loss: 2.0215 - val_accuracy: 0.4306 - val_loss: 1.6377\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.4487 - loss: 1.5744 - val_accuracy: 0.4826 - val_loss: 1.4799\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5000 - loss: 1.4216 - val_accuracy: 0.5146 - val_loss: 1.3924\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5427 - loss: 1.3134 - val_accuracy: 0.5519 - val_loss: 1.2863\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5626 - loss: 1.2457 - val_accuracy: 0.5766 - val_loss: 1.1996\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.5918 - loss: 1.1796 - val_accuracy: 0.6233 - val_loss: 1.1082\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6083 - loss: 1.1265 - val_accuracy: 0.6246 - val_loss: 1.0835\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6315 - loss: 1.0690 - val_accuracy: 0.6555 - val_loss: 1.0251\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.6419 - loss: 1.0288 - val_accuracy: 0.6719 - val_loss: 0.9682\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6580 - loss: 0.9862 - val_accuracy: 0.6627 - val_loss: 0.9624\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n",
    "# convolutional neural network\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[32, 32, 3], name='input'),\n",
    "    DefaultConv2D(filters=32, name='conv1'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool1'),\n",
    "    DefaultConv2D(filters=64, name='conv2'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool2'),\n",
    "    keras.layers.Flatten(name='flatten'),\n",
    "    keras.layers.Dense(128, activation='relu', name='dense1'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32, \n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 42ms/step - accuracy: 0.1457 - loss: 2.2719 - val_accuracy: 0.3377 - val_loss: 1.9098\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 42ms/step - accuracy: 0.2596 - loss: 1.9978 - val_accuracy: 0.3878 - val_loss: 1.7471\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 41ms/step - accuracy: 0.3212 - loss: 1.8554 - val_accuracy: 0.4383 - val_loss: 1.5949\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 41ms/step - accuracy: 0.3761 - loss: 1.7387 - val_accuracy: 0.4596 - val_loss: 1.5330\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 41ms/step - accuracy: 0.4015 - loss: 1.6651 - val_accuracy: 0.4949 - val_loss: 1.4298\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 41ms/step - accuracy: 0.4381 - loss: 1.5824 - val_accuracy: 0.5470 - val_loss: 1.3317\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 41ms/step - accuracy: 0.4625 - loss: 1.5121 - val_accuracy: 0.5531 - val_loss: 1.2887\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - accuracy: 0.4833 - loss: 1.4620 - val_accuracy: 0.5807 - val_loss: 1.2110\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - accuracy: 0.5009 - loss: 1.4054 - val_accuracy: 0.5831 - val_loss: 1.2169\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - accuracy: 0.5182 - loss: 1.3684 - val_accuracy: 0.6011 - val_loss: 1.1461\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n",
    "# convolution with dropout\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[32, 32, 3], name='input'),\n",
    "    DefaultConv2D(filters=64, name='conv1'),\n",
    "    keras.layers.MaxPooling2D(name='pool1'),\n",
    "    DefaultConv2D(filters=128, name='conv2'),\n",
    "    DefaultConv2D(filters=128, name='conv3'),\n",
    "    keras.layers.MaxPooling2D(name='pool2'),\n",
    "    keras.layers.Flatten(name='flatten'),\n",
    "    keras.layers.Dense(128, activation='relu', name='dense1', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu', name='dense2', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "\n",
    "\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32, \n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
